from langchain_google_genai import GoogleGenerativeAI
from langchain.prompts import PromptTemplate

import dotenv
import os

# # завантажити api ключі з папки .env
# dotenv.load_dotenv()
#
# # отримати сам ключ
# api_key = os.getenv('GEMINI_API_KEY')
#
# # створення моделі
#
# llm = GoogleGenerativeAI(
#     model='gemini-2.0-flash',  # назва моделі
#     google_api_key=api_key,  # ваша API
# )

# запит, prompt(підказка)
# prompt engeneering(створення промптів)

# query = "Ти асистент, твоя задача давати відповіді згідно певного документу {rules}"

# створення промпта

# складові промпта
# Хто ти
# базові інструкції(пару речень що треба робити)
# додаткова інформація
# Деталізація(що робити в певних ситуація)
# Приклади
# дані від самого користувача


# prompt = PromptTemplate.from_template(
#     """
#     Ти ввічливий асистент. Твоя задача допомогти людині підготуватись до співбесіди.
#     Ти задаєш питання, користувач відповідає, в кінці співбесіди дай чесний відгук,
#     вкажити що було добре, а де є помилки.
#
#     Використовуй поради з цього документу по проведенню співбесід.
#     Документ: {document}
#
#     ** Якщо користувач починає нервувати коли дає відповіді: **
#         * Якщо користувач починає запинатися, давати нечіткі відповіді,
#         використувавати слова-паразити(наприклад 'Еее', 'Типу', 'Короче')
#         йому потрібно про це вказати та порекомендувати зробити дихальну вправу
#         аби заспокоїтись.
#         * В таких ситуація ти **ПОВИНЕН** змінити тему розмови, трохи знизити
#         емоційне навантаження на користувача, можливо трохи підбадьорити(наприклад
#         сказати що в нього\неї непогано виходить)
#
#     **ПРИКЛАДИ:**
#
#     AI: Чому ви обрали нашу компанію?
#     Користувач: Тому що мені потрібні гроші, а у вас найвища зарплата.
#
#     Помилки користувача: компанії важливо знати що її співробітники справді
#     зацікавленні посадою, модуть запропонувати нові ідеї для комерційних продуктів,
#     Відповідаючи, що вас цікавлять лише гроші створює враження пасивного та меркантильного кандидата,
#     який при першій можливості перейде в іншу компанію
#     Переваги відповіді: переваг немає
#
#     ####
#     Вхідні дані
#
#     Користувач: {user_data}
#     """
# )
#
# document = 'Дуже великий докемнт з порадами'
# user_data = 'Я тут заради грошей'

# так не роблять
# # створення конкретного запити за наведеним шаблоном
# result = prompt.invoke({
#     'document': 'Дуже великий докемнт з порадами',
#     'user_data': 'Я тут заради грошей'
# })
#
# print(result)

# # роблять ось так
#
# # створення ланцюга
# chain = prompt | llm
#
# result = chain.invoke({
#     'document': 'Дуже великий докемнт з порадами',
#     'user_data': 'Я тут заради грошей'
# })
#
# print(result)


# Аналіз тональності
#
# Визнач, чи є тональність тексту позитивною,
# негативною чи нейтральною.

# prompt = PromptTemplate.from_template(
#     """
#     Ти класифікатор текстів. Твоя задача віднести текст до
#     одного з класів: позитивний, негативний, нейтральний.
#     Текст повинен належати лише одному класу, тому давай відповідь одним словом
#     з цих трьох
#
#     **ПРИКЛАДИ:**
#     Текст: мені сподобався цей фільм
#     Клас: позитивний
#
#     Текст: шкода витраченого часу
#     Клас: негативний
#
#     Текст: добре провів час, але вдруге на цей фільм не піду
#     Клас: нейтральний
#
#     Текст: {user_input}
#     Клас:
#     """
# )

# приклади в промптах називають Few-Shot Prompt
# Input:
# Output:

# Human:
# AI:

# Data:
# Result:

# # створення ланцюга
# chain = prompt | llm
#
# user_data = "Обов'язково порекомендую друзям"
#
# response = chain.invoke({
#     'user_input': user_data
# })
# print(response)


# print(12*6 - 2)


# # chain of thought
# data = """У магазині продали 12 коробок. У кожній коробці по 6 пляшок, але в одній коробці не вистачало 2 пляшок.
# Скільки всього пляшок було продано?
#     Дай коротку відповідь одним числом"""
#
# response = llm.invoke(data)
# print(response)


# Термінологія
# Zero-Shot - промпт без прикладів, лише інструкції
# Few-Shot  - промпт з прикладами
# CoT       - chain of thought(ланцюг міркувань). набір кроків щоб розв'язати певну задачу

# ________________________________________
# Напишіть промпт для генерації коду функції для
# вирішення певної задачі.
# Вхідні параметри – мова програмування, опис задачі
# Реалізуйте двома способами:
#  Zero-shot
#  Few-shot


# from langchain_google_genai import GoogleGenerativeAI
# from langchain.prompts import PromptTemplate
# import dotenv
# import os
#
# # завантажити api ключі з папки .env
# dotenv.load_dotenv()
#
# # отримати сам ключ
# api_key = os.getenv('GEMINI_API_KEY')
#
# llm = GoogleGenerativeAI(
#     model='gemini-2.0-flash',  # назва моделі
#     google_api_key=api_key,  # ваша API
# )

# zero_shot_promt = PromptTemplate.from_template(
#     """Ти помічник для написання коду - твоя задача полягає написати функцію мовою яка виконує певне завдання яке вкаже користувач
#
#     Мова програмування: {lang}
#     Завдання: {task}""")
#
# lang = input("Введіть певну мову програмування ")
# task = input("Введіть завдання ")
#
# zero_chain = zero_shot_promt | llm
# result = zero_chain.invoke({"lang": lang, "task": task})
# print(result)

# few_shot_promt = PromptTemplate.from_template(
#     """Ти помічник для написання коду - твоя задача полягає написати функцію мовою яка виконує певне завдання яке вкаже користувач
#
#     Приклади:
#     Мова програмування: Python
#     Завдання: Знайти суму трьох чисел
#     Відповідь: def get_sum(a, b, c):
#   \"\"\"
#   Знаходить суму трьох чисел.
#
#   Args:
#     a: Перше число.
#     b: Друге число.
#     c: Третє число.
#
#   Returns:
#     Суму трьох чисел.
#   \"\"\"
#   return a + b + c
#
#     Мова програмування: {lang}
#     Завдання: {task}
#     Відповідь: """)
#
# lang = input("Введіть певну мову програмування ")
# task = input("Введіть завдання ")
#
# few_chain = few_shot_promt | llm
# result = few_chain.invoke({"lang": lang, "task": task})
# print(result)


from langchain_google_genai import GoogleGenerativeAI
from langchain.prompts import PromptTemplate

import dotenv
import os

# завантажити api ключі з папки .env
dotenv.load_dotenv()

# отримати сам ключ
api_key = os.getenv('GEMINI_API_KEY')

# створення моделі
# Велика мовна модель(llm)

llm = GoogleGenerativeAI(
    model='gemini-2.0-flash',  # назва моделі
    google_api_key=api_key,  # ваша API
)

with open("data\lesson10\products.txt", "r", encoding="UTF-8") as file:
    SPA = file.read()

promt = PromptTemplate.from_template(""" Ты ассистент по услугам СПА-салону. Твоя задача подобрать услуги
спа-салону в соответствии с запросами пользователя. Информация по услугам СПА-салона находится в документе.

Документ по услугам СПА-салона: {SPA}

Вопрос: {ask}

""")
chain = promt | llm

ask = input("запит користувача: ")

result = chain.invoke({'SPA': SPA, 'ask': ask})

print(result)